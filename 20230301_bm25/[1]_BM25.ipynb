{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a96060a524ca47868e2c37bd45a249fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Search",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_39500bb28a0f489e9ce30ba3475e00d0",
            "style": "IPY_MODEL_714edc74247b4590a458487e65e429e5",
            "tooltip": ""
          }
        },
        "39500bb28a0f489e9ce30ba3475e00d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "714edc74247b4590a458487e65e429e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f4d560d302c24337bb751f631c1f649c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_6358865c5ff04d3ea40328431abe7b62",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "id: 296\n",
                  "Participative Management in Relation to Library Effectiveness Lynch, Beverly This paper reviews a recent study on the influence of participative management on library performance.. Because most of the recent theoretical and empirical research being done in this area is ignored and an invalid measure of participation in decision making is used, the study provides no basis for the generalization that in increase in the library staff's participation in decision making will increase the library's effectiveness.. \n",
                  "----------------------------------------------------------------------------------------------------\n",
                  "id: 1015\n",
                  "Participative Management as Related to Personnel Development Marchant, M.P. Theory and practice regarding patterns of decision- making in libraries have been relatively neglected aspects of library administration.  Yet the decisions by which a library attempts to control its operations are of major importance to its welfare and effectiveness.  Recent theories in management and social psychology have addressed themselves to the implications of participative management and group decision-making, and their findings appear to have important applications to libraries, not the least of which is personnel development. \n",
                  "----------------------------------------------------------------------------------------------------\n",
                  "id: 99\n",
                  "Ecological Correlations and the Behavior of Individuals Robinson, W.S. An individual correlation is a correlation in which the statistical object or thing described is indivisible.  The correlation between color and illiteracy for persons in the United States, shown later in Table 1, is an individual correlation, because the kind of thing described is an indivisible unit, a person.  In an individual correlation the variables are descriptive properties of individuals, such as height, income, eye color, or race, and not descriptive statistical constants such as rates or means. In an ecological correlation the statistical object is a group of persons.  The correlation between the percentage of the population which is Negro and the percentage of the population which is illiterate for the 48 states, shown later as Figure 2, is an ecological correlation.  The thing described is the population of a state, and not a single individual.  The variables are percentages, descriptive properties of groups, and not descriptive properties of individuals. \n",
                  "----------------------------------------------------------------------------------------------------\n",
                  "id: 227\n",
                  "A Behavioral Theory of the Firm Cyert, R.M. This book is about the business firm and the way it makes economic decisions.  We propose to make detailed observations of the procedures by which firms make decisions and to use these observations as a basis for a theory of decision making within business organizations.  Our articles of faith are simple.  We believe that, in order to understand contemporary economic decision making, we need to supplement the study of market factors with an examination of the internal operation of the firm - to study the effects of organizational structure and conventional practice on the development of goals, the formation of expectations, and the execution of choices. \n",
                  "----------------------------------------------------------------------------------------------------\n",
                  "id: 856\n",
                  "Concept of an On-Line Computerized Library Catalog Kilgour, Frederick G. A concept for mechanized descriptive cataloging is presented, together with four areas of research programs to be undertaken.. \n",
                  "----------------------------------------------------------------------------------------------------\n"
                ]
              }
            ]
          }
        },
        "6358865c5ff04d3ea40328431abe7b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installs"
      ],
      "metadata": {
        "id": "BjApoMiUVKRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af-sHBTnDk0y",
        "outputId": "a01e3273-52d0-4ca3-85e1-7a5a17f8c74e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-67.4.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (0.38.4)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "cvxpy 1.2.3 requires setuptools<=64.0.2, but you have setuptools 67.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-23.0.1 setuptools-67.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (3.4.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (8.1.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (67.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.10.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.4.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.4\n",
            "    Uninstalling spacy-3.4.4:\n",
            "      Successfully uninstalled spacy-3.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed spacy-3.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-02-28 12:28:57.209342: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-28 12:28:58.546770: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-28 12:28:58.546902: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-28 12:28:58.546925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-02-28 12:29:00.390987: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.4.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.25.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 3.4.1\n",
            "    Uninstalling en-core-web-sm-3.4.1:\n",
            "      Successfully uninstalled en-core-web-sm-3.4.1\n",
            "Successfully installed en-core-web-sm-3.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rank_bm25) (1.22.4)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare CISI Dataset"
      ],
      "metadata": {
        "id": "6CTtaNbbrZDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ],
      "metadata": {
        "id": "FOrY2hVEVBoL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJZi2uuTrPeH",
        "outputId": "3f7ef280-6ddf-4982-eeda-17feca2b3a43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2385920"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "CISI_FILE = 'cisi.tar.gz'\n",
        "CISI_PATH = './CISI'\n",
        "\n",
        "URL = \"http://ir.dcs.gla.ac.uk/resources/test_collections/cisi/cisi.tar.gz\"\n",
        "response = requests.get(URL)\n",
        "open(CISI_FILE, \"wb\").write(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Untar Files"
      ],
      "metadata": {
        "id": "DVXk2_3eVDGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import io\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tarfile\n",
        "\n",
        "with tarfile.open(CISI_FILE) as gz:\n",
        "  gz.extractall(CISI_PATH)"
      ],
      "metadata": {
        "id": "jaPDT8RfrvZS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load CISI dataset"
      ],
      "metadata": {
        "id": "jU_PR2rYVFii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Loading code from: https://www.kaggle.com/code/rid17pawar/sentence-bert\n",
        "\n",
        "def load_data(path):\n",
        "    #_____________ Read data from CISI.ALL file and store in dictinary ________________\n",
        "    \n",
        "    with open(os.path.join(path, 'CISI.ALL')) as f:\n",
        "        lines = \"\"\n",
        "        for l in f.readlines():\n",
        "            lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
        "        lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
        " \n",
        "    doc_set = {}\n",
        "    doc_id = \"\"\n",
        "    doc_text = \"\"\n",
        "\n",
        "    for l in lines:\n",
        "        if l.startswith(\".I\"):\n",
        "            doc_id = l.split(\" \")[1].strip() \n",
        "        elif l.startswith(\".X\"):\n",
        "            doc_set[doc_id] = doc_text.lstrip(\" \")\n",
        "            doc_id = \"\"\n",
        "            doc_text = \"\"\n",
        "        else:\n",
        "            doc_text += l.strip()[3:] + \" \" \n",
        "\n",
        "    print(f\"Number of documents = {len(doc_set)}\")\n",
        "    print(doc_set[\"1\"]) \n",
        "    \n",
        "    \n",
        "    #_____________ Read data from CISI.QRY file and store in dictinary ________________\n",
        "    \n",
        "    with open(os.path.join(path, 'CISI.QRY')) as f:\n",
        "        lines = \"\"\n",
        "        for l in f.readlines():\n",
        "            lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
        "        lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
        "          \n",
        "    qry_set = {}\n",
        "    qry_id = \"\"\n",
        "    for l in lines:\n",
        "        if l.startswith(\".I\"):\n",
        "            qry_id = l.split(\" \")[1].strip() \n",
        "        elif l.startswith(\".W\"):\n",
        "            qry_set[qry_id] = l.strip()[3:]\n",
        "            qry_id = \"\"\n",
        "\n",
        "    print(f\"\\n\\nNumber of queries = {len(qry_set)}\")    \n",
        "    print(qry_set[\"1\"]) \n",
        "    \n",
        "    \n",
        "    #_____________ Read data from CISI.REL file and store in dictinary ________________\n",
        "    \n",
        "    rel_set = {}\n",
        "    with open(os.path.join(path, 'CISI.REL')) as f:\n",
        "        for l in f.readlines():\n",
        "            qry_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0] \n",
        "            doc_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1]\n",
        "\n",
        "            if qry_id in rel_set:\n",
        "                rel_set[qry_id].append(doc_id)\n",
        "            else:\n",
        "                rel_set[qry_id] = []\n",
        "                rel_set[qry_id].append(doc_id)\n",
        "\n",
        "    print(f\"\\n\\nNumber of mappings = {len(rel_set)}\")\n",
        "    print(rel_set[\"1\"]) \n",
        "    \n",
        "    doc_set = {int(id):doc for (id,doc) in doc_set.items()}\n",
        "    qry_set = {int(id):qry for (id,qry) in qry_set.items()}\n",
        "    rel_set = {int(qid):list(map(int, did_lst)) for (qid,did_lst) in rel_set.items()}\n",
        "    \n",
        "    return doc_set, qry_set, rel_set"
      ],
      "metadata": {
        "id": "5oaC19l3sl3p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_set, query_set, rel_set = load_data(CISI_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QURHPH68xc07",
        "outputId": "9e4910ab-932b-4ab4-afa0-02dcc9cbff02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents = 1460\n",
            "18 Editions of the Dewey Decimal Classifications Comaromi, J.P. The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad. \n",
            "\n",
            "\n",
            "Number of queries = 112\n",
            "What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n",
            "\n",
            "\n",
            "Number of mappings = 76\n",
            "['28', '35', '38', '42', '43', '52', '65', '76', '86', '150', '189', '192', '193', '195', '215', '269', '291', '320', '429', '465', '466', '482', '483', '510', '524', '541', '576', '582', '589', '603', '650', '680', '711', '722', '726', '783', '813', '820', '868', '869', '894', '1162', '1164', '1195', '1196', '1281']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing\n",
        "\n",
        "Lemmatization and stop words removal"
      ],
      "metadata": {
        "id": "KvZowxdwgRjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "# apply lemmatization in docs (doc_set) and queries (query_set)\n",
        "# remove stop words\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc_set_lemma = {}\n",
        "for doc, key in tqdm(zip(nlp.pipe(doc_set.values(), batch_size=32, n_process=3, disable=[\"parser\", \"ner\"]), doc_set.keys()), \n",
        "                     total=len(doc_set),\n",
        "                     desc=\"doc_set lemmatization\"):\n",
        "  doc_set_lemma[key] = ' '.join([tok.lemma_ for tok in doc if not tok.is_stop])\n",
        "\n",
        "query_set_lemma = {}\n",
        "for doc, key in tqdm(zip(nlp.pipe(query_set.values(), batch_size=32, n_process=3, disable=[\"parser\", \"ner\"]), query_set.keys()),\n",
        "                     total=len(query_set),\n",
        "                     desc=\"query_set lemmatization\"):\n",
        "  query_set_lemma[key] = ' '.join([tok.lemma_ for tok in doc if not tok.is_stop])\n",
        "  \n",
        "assert len(doc_set_lemma) == len(doc_set)\n",
        "assert len(query_set_lemma) == len(query_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1uBHwhJ7crs",
        "outputId": "cfaa9d08-e4bc-42ce-9f54-f05805d95739"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "doc_set lemmatization: 100%|██████████| 1460/1460 [00:29<00:00, 50.23it/s]\n",
            "query_set lemmatization: 100%|██████████| 112/112 [00:01<00:00, 81.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create bm25 corpus"
      ],
      "metadata": {
        "id": "kWC-b8THVf1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "corpus = [doc for doc in doc_set_lemma.values()]\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)"
      ],
      "metadata": {
        "id": "cP75Kfke19Fl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metric Functions\n",
        "\n",
        "Functions extracted from this [kaggle notebook](https://www.kaggle.com/code/rid17pawar/universal-sentence-encoder)."
      ],
      "metadata": {
        "id": "xCsKQ8pQZNAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recall_k(ground_truth, predictions, k):\n",
        "  avg_recall = 0\n",
        "  for query_id in ground_truth:    \n",
        "    truth_set = set(ground_truth[query_id])\n",
        "    pred_set = set(predictions[query_id][:k])\n",
        "    result = round(len(truth_set & pred_set) / float(len(truth_set)), 2) \n",
        "    avg_recall += result\n",
        "  avg_recall /= len(ground_truth)\n",
        "\n",
        "  return round(avg_recall, 3)"
      ],
      "metadata": {
        "id": "Smy7BXcpZOgD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_k(ground_truth, predictions, k):\n",
        "  avg_precision = 0\n",
        "  for query_id in ground_truth:    \n",
        "    truth_set = set(ground_truth[query_id]) \n",
        "    pred_set = set(predictions[query_id][:k])\n",
        "    result = round(len(truth_set & pred_set) / float(len(pred_set)), 2)\n",
        "    avg_precision += result\n",
        "  avg_precision /= len(ground_truth)\n",
        "\n",
        "  return round(avg_precision, 3)"
      ],
      "metadata": {
        "id": "thnO4Z0nZSU5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_first_relevent_docid(predictions, truth):\n",
        "    for doc_id in predictions:\n",
        "        is_exist = doc_id in truth \n",
        "        if is_exist:\n",
        "            return predictions.index(doc_id)+1 \n",
        "    else:\n",
        "        return -1"
      ],
      "metadata": {
        "id": "CvBVWonNZU86"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mrr(doc_scores, rel_set):\n",
        "    Q = len(rel_set) \n",
        "    cumulative_reciprocal = 0 \n",
        "    \n",
        "    for query_id in rel_set:\n",
        "        first_result = get_first_relevent_docid(doc_scores[query_id], rel_set[query_id])\n",
        "        first_result_rank = len(doc_scores['1'])+1 if first_result<1 else first_result \n",
        "        reciprocal = 1 / first_result_rank\n",
        "        cumulative_reciprocal += reciprocal\n",
        "        \n",
        "    mrr = 1/Q * cumulative_reciprocal \n",
        "    return round(mrr,3)"
      ],
      "metadata": {
        "id": "ZnUoZbfNZYZq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_k(rel_set, doc_scores, K):\n",
        "    Q = len(rel_set) \n",
        "    avg_precision = [] \n",
        "\n",
        "    for query_id in rel_set:\n",
        "        precision_relevance_summation = 0\n",
        "\n",
        "        for k in range(0,K):\n",
        "            # calculate precision@k\n",
        "            truth_set = set(rel_set[query_id])\n",
        "            pred_set = set(doc_scores[query_id][:k+1])\n",
        "            precision_at_k = round(len(truth_set & pred_set) / float(len(pred_set)), 2)  \n",
        "            \n",
        "            rel_k = 1 if doc_scores[query_id][k] in rel_set[query_id] else 0 \n",
        "            precision_relevance_summation += precision_at_k * rel_k \n",
        "\n",
        "        # AP value of query qid\n",
        "        avg_precision_q = precision_relevance_summation / len(rel_set[query_id])\n",
        "        avg_precision.append(avg_precision_q)\n",
        "\n",
        "    map_k = sum(avg_precision) / Q \n",
        "    return round(map_k, 3)"
      ],
      "metadata": {
        "id": "xq5e6HM2Zcrd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "p2dk5ZLIVrcq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate scores"
      ],
      "metadata": {
        "id": "_j_F6bFJlVP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_doc_scores = {}\n",
        "query_doc_sorted = {}\n",
        "\n",
        "for query_id in query_set_lemma:\n",
        "  query_txt = query_set_lemma[query_id]\n",
        "  tokenized_query = query_txt.split(\" \")\n",
        "  doc_scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "  # starts in 1 because documents ids start with 1\n",
        "  doc_scores_dict = {idx: score for idx, score in enumerate(doc_scores, start=1)}\n",
        "  \n",
        "  query_doc_sorted[query_id] = sorted(doc_scores_dict, key=doc_scores_dict.get, reverse=True) \n",
        "\n",
        "  query_doc_scores[query_id] = dict(sorted(doc_scores_dict.items(), key=lambda x:x[1], reverse=True))"
      ],
      "metadata": {
        "id": "BQSVKKj0Vtoy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "1PcP913TlWMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Recall@10 = {recall_k(rel_set, query_doc_sorted, 10)}\") #Top-10 results"
      ],
      "metadata": {
        "id": "sAzuV1aaYcHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80f6b801-3655-449e-93bc-f97d03a72890"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall@10 = 0.103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Precision@10 = {precision_k(rel_set, query_doc_sorted, 10)}\") #Top-10 results"
      ],
      "metadata": {
        "id": "6IECD531ZpXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f0a432f-a456-4421-b3d7-c22f9fed6e15"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@10 = 0.261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mrr_result = mrr(query_doc_sorted, rel_set)\n",
        "print(f\"Mean Reciprocal Rank (MRR): {mrr_result}\")"
      ],
      "metadata": {
        "id": "hZipJMNHZwqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "255da664-2209-495f-f4de-de91cf8f30e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Reciprocal Rank (MRR): 0.541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "map_10 = map_k(rel_set, query_doc_sorted, K=10)\n",
        "print(f\"MAP@10 (MAP)= {map_10}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgcAvL776bTB",
        "outputId": "c1cab14f-5a4e-4b21-bdb4-f6a79760024f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@10 (MAP)= 0.056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search System"
      ],
      "metadata": {
        "id": "W-WmLcnLmEFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_search(query_txt, topk):\n",
        "  \"\"\"Returns a sorted list of the topk ids of relevant document given \n",
        "  a query text.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    query_txt : str\n",
        "        A query text\n",
        "    topk      : int\n",
        "        total numer of relevant documents\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        sorted list of the topk ids of relevant document given the query text\n",
        "    \"\"\"\n",
        "\n",
        "  tokenized_query = query_txt.split(\" \")\n",
        "  doc_scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "  doc_scores_dict = {idx: score for idx, score in enumerate(doc_scores, start=1)}\n",
        "  query_doc_sorted = sorted(doc_scores_dict, key=doc_scores_dict.get, reverse=True) \n",
        "\n",
        "  return query_doc_sorted[:topk]"
      ],
      "metadata": {
        "id": "_56BKxA7mXUP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title String fields\n",
        "\n",
        "query = 'What problems and concerns are there in making up descriptive titles?' #@param {type:\"string\"}\n",
        "topk = 5 #@param [5, 10, 20, 30]"
      ],
      "metadata": {
        "id": "0rDk8SH0mFPn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "button = widgets.Button(description=\"Search\")\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_button_clicked(b):\n",
        "  search_result = make_search(query, topk)\n",
        "  # Display the message within the output widget.\n",
        "  with output:\n",
        "    for doc_id in search_result:\n",
        "      print('id: {0}'.format(doc_id))\n",
        "      print(doc_set[doc_id])\n",
        "      print('-'*100)\n",
        "\n",
        "button.on_click(on_button_clicked)\n",
        "display(button, output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639,
          "referenced_widgets": [
            "a96060a524ca47868e2c37bd45a249fe",
            "39500bb28a0f489e9ce30ba3475e00d0",
            "714edc74247b4590a458487e65e429e5",
            "f4d560d302c24337bb751f631c1f649c",
            "6358865c5ff04d3ea40328431abe7b62"
          ]
        },
        "id": "-UWSy1vkmSWp",
        "outputId": "e44380c9-8c9c-4674-9ff9-9c675b6e9c21"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Search', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a96060a524ca47868e2c37bd45a249fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4d560d302c24337bb751f631c1f649c"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}